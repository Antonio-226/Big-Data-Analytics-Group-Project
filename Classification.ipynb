{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>water_temperature</th>\n",
       "      <th>wind_gust_max_10min</th>\n",
       "      <th>wind_speed_avg_10min</th>\n",
       "      <th>wind_force_avg_10min</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>windchill</th>\n",
       "      <th>barometric_pressure_qfe</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour_14.0</th>\n",
       "      <th>Hour_15.0</th>\n",
       "      <th>Hour_16.0</th>\n",
       "      <th>Hour_17.0</th>\n",
       "      <th>Hour_18.0</th>\n",
       "      <th>Hour_19.0</th>\n",
       "      <th>Hour_20.0</th>\n",
       "      <th>Hour_21.0</th>\n",
       "      <th>Hour_22.0</th>\n",
       "      <th>Hour_23.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-01 00:30:00</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>1785</td>\n",
       "      <td>2.20</td>\n",
       "      <td>974.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01 01:30:00</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.16</td>\n",
       "      <td>973.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01 02:30:00</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1159</td>\n",
       "      <td>2.58</td>\n",
       "      <td>973.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01 02:30:00</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1159</td>\n",
       "      <td>2.58</td>\n",
       "      <td>973.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01 03:30:00</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.16</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1122</td>\n",
       "      <td>2.54</td>\n",
       "      <td>973.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 date  air_temperature  water_temperature  \\\n",
       "0           0  2011-01-01 00:30:00         2.233333               5.20   \n",
       "1           1  2011-01-01 01:30:00         2.380000               5.20   \n",
       "2           2  2011-01-01 02:30:00         2.580000               5.14   \n",
       "3           3  2011-01-01 02:30:00         2.580000               5.14   \n",
       "4           4  2011-01-01 03:30:00         2.500000               5.16   \n",
       "\n",
       "   wind_gust_max_10min  wind_speed_avg_10min  wind_force_avg_10min  \\\n",
       "0                  2.4              1.216667              1.216667   \n",
       "1                  2.8              0.860000              0.860000   \n",
       "2                  1.2              0.340000              0.340000   \n",
       "3                  1.2              0.340000              0.340000   \n",
       "4                  1.9              0.520000              0.520000   \n",
       "\n",
       "   wind_direction  windchill  barometric_pressure_qfe  ...  Hour_14.0  \\\n",
       "0            1785       2.20                   974.55  ...          0   \n",
       "1            1076       2.16                   973.98  ...          0   \n",
       "2            1159       2.58                   973.64  ...          0   \n",
       "3            1159       2.58                   973.64  ...          0   \n",
       "4            1122       2.54                   973.42  ...          0   \n",
       "\n",
       "   Hour_15.0  Hour_16.0  Hour_17.0  Hour_18.0  Hour_19.0  Hour_20.0  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   Hour_21.0  Hour_22.0  Hour_23.0  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>water_temperature</th>\n",
       "      <th>wind_gust_max_10min</th>\n",
       "      <th>wind_speed_avg_10min</th>\n",
       "      <th>wind_force_avg_10min</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>windchill</th>\n",
       "      <th>barometric_pressure_qfe</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour_14.0</th>\n",
       "      <th>Hour_15.0</th>\n",
       "      <th>Hour_16.0</th>\n",
       "      <th>Hour_17.0</th>\n",
       "      <th>Hour_18.0</th>\n",
       "      <th>Hour_19.0</th>\n",
       "      <th>Hour_20.0</th>\n",
       "      <th>Hour_21.0</th>\n",
       "      <th>Hour_22.0</th>\n",
       "      <th>Hour_23.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-01 00:30:00</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>1785</td>\n",
       "      <td>2.20</td>\n",
       "      <td>974.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01 01:30:00</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.16</td>\n",
       "      <td>973.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01 02:30:00</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1159</td>\n",
       "      <td>2.58</td>\n",
       "      <td>973.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01 02:30:00</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1159</td>\n",
       "      <td>2.58</td>\n",
       "      <td>973.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01 03:30:00</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.16</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1122</td>\n",
       "      <td>2.54</td>\n",
       "      <td>973.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 date  air_temperature  water_temperature  \\\n",
       "0           0  2011-01-01 00:30:00         2.233333               5.20   \n",
       "1           1  2011-01-01 01:30:00         2.380000               5.20   \n",
       "2           2  2011-01-01 02:30:00         2.580000               5.14   \n",
       "3           3  2011-01-01 02:30:00         2.580000               5.14   \n",
       "4           4  2011-01-01 03:30:00         2.500000               5.16   \n",
       "\n",
       "   wind_gust_max_10min  wind_speed_avg_10min  wind_force_avg_10min  \\\n",
       "0                  2.4              1.216667              1.216667   \n",
       "1                  2.8              0.860000              0.860000   \n",
       "2                  1.2              0.340000              0.340000   \n",
       "3                  1.2              0.340000              0.340000   \n",
       "4                  1.9              0.520000              0.520000   \n",
       "\n",
       "   wind_direction  windchill  barometric_pressure_qfe  ...  Hour_14.0  \\\n",
       "0            1785       2.20                   974.55  ...          0   \n",
       "1            1076       2.16                   973.98  ...          0   \n",
       "2            1159       2.58                   973.64  ...          0   \n",
       "3            1159       2.58                   973.64  ...          0   \n",
       "4            1122       2.54                   973.42  ...          0   \n",
       "\n",
       "   Hour_15.0  Hour_16.0  Hour_17.0  Hour_18.0  Hour_19.0  Hour_20.0  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   Hour_21.0  Hour_22.0  Hour_23.0  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'air_temperature', 'water_temperature',\n",
       "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
       "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
       "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
       "       'water_level', 'AccidentInvolvingPedestrian',\n",
       "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
       "       'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
       "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
       "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
       "       'AccidentType_at9', 'AccidentSeverityCategory_as2',\n",
       "       'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4',\n",
       "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
       "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
       "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
       "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
       "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
       "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
       "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
       "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
       "       'Hour_22.0', 'Hour_23.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Fig.1) Accident Distribution', fontweight = 'bold')\n",
    "sns.countplot(x = 'Accident', data=df, facecolor=(0, 0, 0, 0),\n",
    "                   linewidth=5, edgecolor=sns.color_palette(\"dark\", 3))\n",
    "plt.ylabel('Count', fontweight = 'bold')\n",
    "plt.xlabel('Accident', fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new dataset containing the relevant variables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[~df.columns.isin([col for col in df.columns if col.startswith('Accident') and col != 'Accident'])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Input and Output Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[~df.columns.isin(['date', 'Accident', 'Unnamed: 0'])]]\n",
    "y = df['Accident']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create train and test datasets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Custom Dataloaders:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Neural Net Architecture**\n",
    "<img src=\"https://miro.medium.com/max/1400/0*CLjAAd7s6o0yfEYZ.jpg\"\n",
    "     alt=\"NN\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 53.\n",
    "        self.layer_1 = nn.Linear(53, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binaryClassification(\n",
      "  (layer_1): Linear(in_features=53, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = binaryClassification()\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.58411 | Acc: 69.639\n",
      "Epoch 002: | Loss: 0.56814 | Acc: 70.937\n",
      "Epoch 003: | Loss: 0.56378 | Acc: 71.112\n",
      "Epoch 004: | Loss: 0.56267 | Acc: 71.288\n",
      "Epoch 005: | Loss: 0.56034 | Acc: 71.490\n",
      "Epoch 006: | Loss: 0.55912 | Acc: 71.437\n",
      "Epoch 007: | Loss: 0.55742 | Acc: 71.758\n",
      "Epoch 008: | Loss: 0.55565 | Acc: 71.648\n",
      "Epoch 009: | Loss: 0.55540 | Acc: 71.565\n",
      "Epoch 010: | Loss: 0.55298 | Acc: 71.713\n",
      "Epoch 011: | Loss: 0.55259 | Acc: 71.923\n",
      "Epoch 012: | Loss: 0.55072 | Acc: 71.908\n",
      "Epoch 013: | Loss: 0.54857 | Acc: 71.998\n",
      "Epoch 014: | Loss: 0.54720 | Acc: 72.244\n",
      "Epoch 015: | Loss: 0.54645 | Acc: 72.289\n",
      "Epoch 016: | Loss: 0.54560 | Acc: 72.182\n",
      "Epoch 017: | Loss: 0.54463 | Acc: 72.426\n",
      "Epoch 018: | Loss: 0.54396 | Acc: 72.293\n",
      "Epoch 019: | Loss: 0.54231 | Acc: 72.641\n",
      "Epoch 020: | Loss: 0.54138 | Acc: 72.548\n",
      "Epoch 021: | Loss: 0.53973 | Acc: 72.677\n",
      "Epoch 022: | Loss: 0.53918 | Acc: 72.656\n",
      "Epoch 023: | Loss: 0.53912 | Acc: 72.731\n",
      "Epoch 024: | Loss: 0.53753 | Acc: 72.937\n",
      "Epoch 025: | Loss: 0.53692 | Acc: 72.897\n",
      "Epoch 026: | Loss: 0.53524 | Acc: 73.028\n",
      "Epoch 027: | Loss: 0.53505 | Acc: 73.009\n",
      "Epoch 028: | Loss: 0.53411 | Acc: 73.011\n",
      "Epoch 029: | Loss: 0.53265 | Acc: 73.359\n",
      "Epoch 030: | Loss: 0.53194 | Acc: 73.169\n",
      "Epoch 031: | Loss: 0.53123 | Acc: 73.148\n",
      "Epoch 032: | Loss: 0.53098 | Acc: 73.285\n",
      "Epoch 033: | Loss: 0.53058 | Acc: 73.254\n",
      "Epoch 034: | Loss: 0.53010 | Acc: 73.408\n",
      "Epoch 035: | Loss: 0.52858 | Acc: 73.422\n",
      "Epoch 036: | Loss: 0.52873 | Acc: 73.273\n",
      "Epoch 037: | Loss: 0.52727 | Acc: 73.519\n",
      "Epoch 038: | Loss: 0.52821 | Acc: 73.429\n",
      "Epoch 039: | Loss: 0.52617 | Acc: 73.639\n",
      "Epoch 040: | Loss: 0.52533 | Acc: 73.733\n",
      "Epoch 041: | Loss: 0.52427 | Acc: 73.507\n",
      "Epoch 042: | Loss: 0.52380 | Acc: 73.887\n",
      "Epoch 043: | Loss: 0.52402 | Acc: 73.701\n",
      "Epoch 044: | Loss: 0.52333 | Acc: 73.873\n",
      "Epoch 045: | Loss: 0.52309 | Acc: 73.585\n",
      "Epoch 046: | Loss: 0.52271 | Acc: 73.772\n",
      "Epoch 047: | Loss: 0.52084 | Acc: 73.989\n",
      "Epoch 048: | Loss: 0.52197 | Acc: 73.956\n",
      "Epoch 049: | Loss: 0.52135 | Acc: 73.882\n",
      "Epoch 050: | Loss: 0.52018 | Acc: 74.068\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.72     16332\n",
      "           1       0.68      0.68      0.68     14055\n",
      "\n",
      "    accuracy                           0.70     30387\n",
      "   macro avg       0.70      0.70      0.70     30387\n",
      "weighted avg       0.70      0.70      0.70     30387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7452760523000739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "windchill                  0.064193\n",
       "wind_speed_avg_10min       0.059366\n",
       "wind_gust_max_10min        0.054802\n",
       "wind_force_avg_10min       0.055021\n",
       "wind_direction             0.053887\n",
       "water_temperature          0.063671\n",
       "water_level                0.062583\n",
       "precipitation              0.063436\n",
       "humidity                   0.011333\n",
       "global_radiation           0.059130\n",
       "dew_point                  0.121014\n",
       "barometric_pressure_qfe    0.069132\n",
       "air_temperature            0.049987\n",
       "WeekDay_Wednesday          0.006500\n",
       "WeekDay_Tuesday            0.008793\n",
       "WeekDay_Thursday           0.017599\n",
       "WeekDay_Sunday             0.006686\n",
       "WeekDay_Saturday           0.006359\n",
       "WeekDay_Monday             0.006627\n",
       "Month_9.0                  0.002805\n",
       "Month_8.0                  0.003303\n",
       "Month_7.0                  0.003740\n",
       "Month_6.0                  0.003985\n",
       "Month_5.0                  0.003703\n",
       "Month_4.0                  0.003415\n",
       "Month_3.0                  0.003345\n",
       "Month_2.0                  0.003866\n",
       "Month_12.0                 0.004020\n",
       "Month_11.0                 0.003707\n",
       "Month_10.0                 0.003467\n",
       "Hour_9.0                   0.006251\n",
       "Hour_8.0                   0.006795\n",
       "Hour_7.0                   0.009206\n",
       "Hour_6.0                   0.009250\n",
       "Hour_5.0                   0.005705\n",
       "Hour_4.0                   0.004724\n",
       "Hour_3.0                   0.004434\n",
       "Hour_23.0                  0.003606\n",
       "Hour_22.0                  0.003128\n",
       "Hour_21.0                  0.003073\n",
       "Hour_20.0                  0.003136\n",
       "Hour_2.0                   0.003339\n",
       "Hour_19.0                  0.003230\n",
       "Hour_18.0                  0.003566\n",
       "Hour_17.0                  0.003363\n",
       "Hour_16.0                  0.005986\n",
       "Hour_15.0                  0.012190\n",
       "Hour_14.0                  0.011090\n",
       "Hour_13.0                  0.005727\n",
       "Hour_12.0                  0.004200\n",
       "Hour_11.0                  0.002867\n",
       "Hour_10.0                  0.002725\n",
       "Hour_1.0                   0.002937\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output label\n",
    "target = np.array(df['Accident'])\n",
    "\n",
    "#input features\n",
    "features = df[df.columns[~df.columns.isin(['date','Accident', 'Unnamed: 0'])]]\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "#split dataset into training and testing\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "target, test_size = 0.25, random_state = 10)\n",
    "\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "clf = RandomForestClassifier(n_estimators= 100)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train_features, train_target)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_target, predictions))\n",
    "\n",
    "#check contributions to prediction\n",
    "feature_names = df.columns[~df.columns.isin(['date','Accident', 'Unnamed: 0'])]\n",
    "feature_imp = pd.Series(clf.feature_importances_, index=feature_names.sort_values(ascending=False))\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Mulit-Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "<br>\n",
    "***a)***\n",
    "<br>\n",
    "Multi-class prediction for AccidentSeverity\n",
    "<br>\n",
    "***b)***\n",
    "<br>\n",
    "Multi-class prediction for AccidentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'air_temperature', 'water_temperature',\n",
       "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
       "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
       "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
       "       'water_level', 'AccidentInvolvingPedestrian',\n",
       "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
       "       'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
       "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
       "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
       "       'AccidentType_at9', 'AccidentSeverityCategory_as2',\n",
       "       'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4',\n",
       "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
       "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
       "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
       "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
       "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
       "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
       "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
       "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
       "       'Hour_22.0', 'Hour_23.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Accident Severity prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Input and Output Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'air_temperature', 'water_temperature',\n",
       "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
       "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
       "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
       "       'water_level', 'AccidentInvolvingPedestrian',\n",
       "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
       "       'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
       "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
       "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
       "       'AccidentType_at9', 'AccidentSeverityCategory_as2',\n",
       "       'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4',\n",
       "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
       "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
       "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
       "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
       "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
       "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
       "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
       "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
       "       'Hour_22.0', 'Hour_23.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Unnamed: 0', 'date', 'AccidentInvolvingPedestrian',\n",
    "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
    "        'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
    "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
    "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
    "       'AccidentType_at9']\n",
    "\n",
    "#create data frame for Random Forest prediction\n",
    "df_nn_acc_type = df[df.columns[~df.columns.isin(cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_nn_acc_type[df_nn_acc_type.columns[~df_nn_acc_type.columns.isin(cols)]]\n",
    "y = np.array(df_nn_acc_type[['AccidentSeverityCategory_as2', 'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-62327dc4adf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m train_data = trainData(torch.FloatTensor(X_train), \n\u001b[1;32m---> 16\u001b[1;33m                        torch.FloatTensor(y_train))\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m## test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mtestData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 53.\n",
    "        self.layer_1 = nn.Linear(53, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = binaryClassification()\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['air_temperature', 'water_temperature', 'wind_gust_max_10min',\n",
       "       'wind_speed_avg_10min', 'wind_force_avg_10min', 'wind_direction',\n",
       "       'windchill', 'barometric_pressure_qfe', 'precipitation', 'dew_point',\n",
       "       'global_radiation', 'humidity', 'water_level',\n",
       "       'AccidentSeverityCategory_as2', 'AccidentSeverityCategory_as3',\n",
       "       'AccidentSeverityCategory_as4', 'WeekDay_Monday', 'WeekDay_Saturday',\n",
       "       'WeekDay_Sunday', 'WeekDay_Thursday', 'WeekDay_Tuesday',\n",
       "       'WeekDay_Wednesday', 'Month_2.0', 'Month_3.0', 'Month_4.0', 'Month_5.0',\n",
       "       'Month_6.0', 'Month_7.0', 'Month_8.0', 'Month_9.0', 'Month_10.0',\n",
       "       'Month_11.0', 'Month_12.0', 'Hour_1.0', 'Hour_2.0', 'Hour_3.0',\n",
       "       'Hour_4.0', 'Hour_5.0', 'Hour_6.0', 'Hour_7.0', 'Hour_8.0', 'Hour_9.0',\n",
       "       'Hour_10.0', 'Hour_11.0', 'Hour_12.0', 'Hour_13.0', 'Hour_14.0',\n",
       "       'Hour_15.0', 'Hour_16.0', 'Hour_17.0', 'Hour_18.0', 'Hour_19.0',\n",
       "       'Hour_20.0', 'Hour_21.0', 'Hour_22.0', 'Hour_23.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of columns that are not necessary for prediction\n",
    "cols = ['Unnamed: 0', 'date', 'AccidentInvolvingPedestrian',\n",
    "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
    "        'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
    "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
    "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
    "       'AccidentType_at9']\n",
    "\n",
    "\n",
    "#create data frame for Random Forest prediction\n",
    "df_rf_acc_type = df[df.columns[~df.columns.isin(cols)]]\n",
    "df_rf_acc_type.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define targets and labels and run the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6541853090656358\n"
     ]
    }
   ],
   "source": [
    "#output label\n",
    "output_class = df_rf_acc_type[[col for col in df_rf_acc_type.columns if col.startswith('Accident')]]\n",
    "target = np.array(output_class)\n",
    "\n",
    "#input features\n",
    "features = df_rf_acc_type[df_rf_acc_type.columns[~df_rf_acc_type.columns.isin(output_class)]]\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "#split dataset into training and testing\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "target, test_size = 0.25, random_state = 10)\n",
    "\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "clf = RandomForestClassifier(n_estimators= 250)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train_features, train_target)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Accident Type prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Unnamed: 0', 'date', 'AccidentInvolvingPedestrian',\n",
    "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
    "        'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
    "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
    "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
    "       'AccidentType_at9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame for Random Forest prediction\n",
    "df_nn_acc_type = df[df.columns[~df.columns.isin(cols)]]\n",
    "\n",
    "X = df_nn_acc_type[df_nn_acc_type.columns[~df_nn_acc_type.columns.isin(cols)]]\n",
    "y = df_nn_acc_type[['AccidentSeverityCategory_as2', 'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 53.\n",
    "        self.layer_1 = nn.Linear(53, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = binaryClassification()\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of columns that are necessary for prediction\n",
    "cols = ['air_temperature', 'water_temperature',\n",
    "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
    "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
    "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
    "       'water_level', 'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
    "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
    "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
    "       'AccidentType_at9',\n",
    "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
    "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
    "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
    "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
    "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
    "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
    "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
    "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
    "       'Hour_22.0', 'Hour_23.0']\n",
    "\n",
    "#Create data frame for Random Forest prediction\n",
    "df_rf_acc_sev = df[df.columns[df.columns.isin(cols)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define targets and labels and run the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output label\n",
    "output_class = df_rf_acc_sev[[col for col in df_rf_acc_sev.columns if col.startswith('Accident')]]\n",
    "target = np.array(output_class)\n",
    "\n",
    "#input features\n",
    "features = df_rf_acc_sev[df_rf_acc_sev.columns[~df_rf_acc_sev.columns.isin(output_class)]]\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "#split dataset into training and testing\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "target, test_size = 0.25, random_state = 11)\n",
    "\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "clf = RandomForestClassifier(n_estimators= 130)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train_features, train_target)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_target, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
