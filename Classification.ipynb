{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>water_temperature</th>\n",
       "      <th>wind_gust_max_10min</th>\n",
       "      <th>wind_speed_avg_10min</th>\n",
       "      <th>wind_force_avg_10min</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>windchill</th>\n",
       "      <th>barometric_pressure_qfe</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour_14.0</th>\n",
       "      <th>Hour_15.0</th>\n",
       "      <th>Hour_16.0</th>\n",
       "      <th>Hour_17.0</th>\n",
       "      <th>Hour_18.0</th>\n",
       "      <th>Hour_19.0</th>\n",
       "      <th>Hour_20.0</th>\n",
       "      <th>Hour_21.0</th>\n",
       "      <th>Hour_22.0</th>\n",
       "      <th>Hour_23.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-01 00:30:00</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>1785</td>\n",
       "      <td>2.20</td>\n",
       "      <td>974.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01 01:30:00</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.16</td>\n",
       "      <td>973.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01 02:30:00</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1159</td>\n",
       "      <td>2.58</td>\n",
       "      <td>973.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01 02:30:00</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1159</td>\n",
       "      <td>2.58</td>\n",
       "      <td>973.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01 03:30:00</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.16</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1122</td>\n",
       "      <td>2.54</td>\n",
       "      <td>973.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 date  air_temperature  water_temperature  \\\n",
       "0           0  2011-01-01 00:30:00         2.233333               5.20   \n",
       "1           1  2011-01-01 01:30:00         2.380000               5.20   \n",
       "2           2  2011-01-01 02:30:00         2.580000               5.14   \n",
       "3           3  2011-01-01 02:30:00         2.580000               5.14   \n",
       "4           4  2011-01-01 03:30:00         2.500000               5.16   \n",
       "\n",
       "   wind_gust_max_10min  wind_speed_avg_10min  wind_force_avg_10min  \\\n",
       "0                  2.4              1.216667              1.216667   \n",
       "1                  2.8              0.860000              0.860000   \n",
       "2                  1.2              0.340000              0.340000   \n",
       "3                  1.2              0.340000              0.340000   \n",
       "4                  1.9              0.520000              0.520000   \n",
       "\n",
       "   wind_direction  windchill  barometric_pressure_qfe  ...  Hour_14.0  \\\n",
       "0            1785       2.20                   974.55  ...          0   \n",
       "1            1076       2.16                   973.98  ...          0   \n",
       "2            1159       2.58                   973.64  ...          0   \n",
       "3            1159       2.58                   973.64  ...          0   \n",
       "4            1122       2.54                   973.42  ...          0   \n",
       "\n",
       "   Hour_15.0  Hour_16.0  Hour_17.0  Hour_18.0  Hour_19.0  Hour_20.0  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   Hour_21.0  Hour_22.0  Hour_23.0  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'Accident', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[~df.columns.isin([col for col in df.columns if col.startswith('Accident') and col != 'Accident'])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Input and Output Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[~df.columns.isin(['date', 'Accident', 'Unnamed: 0'])]]\n",
    "y = df['Accident']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create train and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Custom Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Neural Net Architecture**\n",
    "<img src=\"https://miro.medium.com/max/1400/0*CLjAAd7s6o0yfEYZ.jpg\"\n",
    "     alt=\"NN\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 53.\n",
    "        self.layer_1 = nn.Linear(53, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = binaryClassification()\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output label\n",
    "target = np.array(df['Accident'])\n",
    "\n",
    "#input features\n",
    "features = df[df.columns[~df.columns.isin(['date','Accident', 'Unnamed: 0'])]]\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "#split dataset into training and testing\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "target, test_size = 0.25, random_state = 10)\n",
    "\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "clf = RandomForestClassifier(n_estimators= 100)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train_features, train_target)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_target, predictions))\n",
    "\n",
    "#check contributions to prediction\n",
    "feature_names = df.columns[~df.columns.isin(['date','Accident', 'Unnamed: 0'])]\n",
    "feature_imp = pd.Series(clf.feature_importances_, index=feature_names.sort_values(ascending=False))\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Mulit-Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "<br>\n",
    "***a)***\n",
    "<br>\n",
    "Multi-class prediction for AccidentSeverity\n",
    "<br>\n",
    "***b)***\n",
    "<br>\n",
    "Multi-class prediction for AccidentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'air_temperature', 'water_temperature',\n",
       "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
       "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
       "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
       "       'water_level', 'AccidentInvolvingPedestrian',\n",
       "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
       "       'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
       "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
       "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
       "       'AccidentType_at9', 'AccidentSeverityCategory_as2',\n",
       "       'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4',\n",
       "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
       "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
       "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
       "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
       "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
       "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
       "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
       "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
       "       'Hour_22.0', 'Hour_23.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Prediction of AccidentType**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Unnamed: 0', 'date', 'AccidentInvolvingPedestrian',\n",
    "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
    "        'AccidentSeverityCategory_as2','AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf_acc_type = df[df.columns[~df.columns.isin(cols)]]\n",
    "df_rf_acc_type.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6439772381738412\n"
     ]
    }
   ],
   "source": [
    "#output label\n",
    "output_class = df_rf_acc_type[[col for col in df_rf_acc_type.columns if col.startswith('Accident')]]\n",
    "target = np.array(output_class)\n",
    "\n",
    "#input features\n",
    "features = df_rf_acc_type[df_rf_acc_type.columns[~df_rf_acc_type.columns.isin(output_class)]]\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "#split dataset into training and testing\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "target, test_size = 0.25, random_state = 10)\n",
    "\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "clf = RandomForestClassifier(n_estimators= 250)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train_features, train_target)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Prediction of AccidentSeverity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'air_temperature', 'water_temperature',\n",
       "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
       "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
       "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
       "       'water_level', 'AccidentInvolvingPedestrian',\n",
       "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
       "       'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
       "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
       "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
       "       'AccidentType_at9', 'AccidentSeverityCategory_as2',\n",
       "       'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4',\n",
       "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
       "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
       "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
       "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
       "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
       "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
       "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
       "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
       "       'Hour_22.0', 'Hour_23.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['air_temperature', 'water_temperature',\n",
    "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
    "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
    "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
    "       'water_level', 'AccidentSeverityCategory_as2',\n",
    "       'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4',\n",
    "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
    "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
    "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
    "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
    "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
    "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
    "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
    "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
    "       'Hour_22.0', 'Hour_23.0']\n",
    "\n",
    "df_rf_acc_sev = df[df.columns[df.columns.isin(cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6632205377698623\n"
     ]
    }
   ],
   "source": [
    "#output label\n",
    "output_class = df_rf_acc_sev[[col for col in df_rf_acc_sev.columns if col.startswith('Accident')]]\n",
    "target = np.array(output_class)\n",
    "\n",
    "#input features\n",
    "features = df_rf_acc_sev[df_rf_acc_sev.columns[~df_rf_acc_sev.columns.isin(output_class)]]\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "#split dataset into training and testing\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "target, test_size = 0.25, random_state = 11)\n",
    "\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "clf = RandomForestClassifier(n_estimators= 130)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train_features, train_target)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_target, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
