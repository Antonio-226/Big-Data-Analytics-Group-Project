{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f12ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ba269",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e952b75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794102a",
   "metadata": {},
   "source": [
    "**Class Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Fig.1) Accident Distribution', fontweight = 'bold')\n",
    "sns.countplot(x = 'Accident', data=df, facecolor=(0, 0, 0, 0),\n",
    "                   linewidth=5, edgecolor=sns.color_palette(\"dark\", 3))\n",
    "plt.ylabel('Count', fontweight = 'bold')\n",
    "plt.xlabel('Accident', fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aeadbf",
   "metadata": {},
   "source": [
    "## I) Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2846a",
   "metadata": {},
   "source": [
    "**Create new dataset containing the relevant variables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ff74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[~df.columns.isin([col for col in df.columns if col.startswith('Accident') and col != 'Accident'])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eb78fa",
   "metadata": {},
   "source": [
    "### a) Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a0af5",
   "metadata": {},
   "source": [
    "**Create Input and Output Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[~df.columns.isin(['date', 'Accident', 'Unnamed: 0'])]]\n",
    "y = df['Accident']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444bb74",
   "metadata": {},
   "source": [
    "**Create train and test datasets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae0c662",
   "metadata": {},
   "source": [
    "**Model Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a76194",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b83e1",
   "metadata": {},
   "source": [
    "**Define Custom Dataloaders:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd161cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22702a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8116d5",
   "metadata": {},
   "source": [
    "**Define Neural Net Architecture**\n",
    "<img src=\"https://miro.medium.com/max/1400/0*CLjAAd7s6o0yfEYZ.jpg\"\n",
    "     alt=\"NN\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a9354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 53.\n",
    "        self.layer_1 = nn.Linear(53, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afebb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = binaryClassification()\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98611ed8",
   "metadata": {},
   "source": [
    "**Accuracy function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e703e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f014580",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch, y_batch in train_loader:\n",
    "    print(y_batch.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad83f6",
   "metadata": {},
   "source": [
    "**Train the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f964fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d302c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df507187",
   "metadata": {},
   "source": [
    "**Test the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560aa36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b129a",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8327d2",
   "metadata": {},
   "source": [
    "### b) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e5177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output label\n",
    "target = np.array(df['Accident'])\n",
    "\n",
    "#input features\n",
    "features = df[df.columns[~df.columns.isin(['date','Accident', 'Unnamed: 0'])]]\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "#split dataset into training and testing\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "target, test_size = 0.25, random_state = 10)\n",
    "\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "clf = RandomForestClassifier(n_estimators= 100)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train_features, train_target)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_target, predictions))\n",
    "\n",
    "#check contributions to prediction\n",
    "feature_names = df.columns[~df.columns.isin(['date','Accident', 'Unnamed: 0'])]\n",
    "feature_imp = pd.Series(clf.feature_importances_, index=feature_names.sort_values(ascending=False))\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3581b97",
   "metadata": {},
   "source": [
    "## II) Mulit-Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da5279",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "<br>\n",
    "***a)***\n",
    "<br>\n",
    "Multi-class prediction for AccidentSeverity\n",
    "<br>\n",
    "***b)***\n",
    "<br>\n",
    "Multi-class prediction for AccidentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66d3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7b64a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'air_temperature', 'water_temperature',\n",
       "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
       "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
       "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
       "       'water_level', 'AccidentInvolvingPedestrian',\n",
       "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
       "       'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
       "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
       "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
       "       'AccidentType_at9', 'AccidentSeverityCategory_as2',\n",
       "       'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4',\n",
       "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
       "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
       "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
       "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
       "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
       "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
       "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
       "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
       "       'Hour_22.0', 'Hour_23.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda1d31",
   "metadata": {},
   "source": [
    "### - Accident Severity prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87082862",
   "metadata": {},
   "source": [
    "### i) Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa117dff",
   "metadata": {},
   "source": [
    "**Create Input and Output Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44403c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'date', 'air_temperature', 'water_temperature',\n",
       "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
       "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
       "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
       "       'water_level', 'AccidentInvolvingPedestrian',\n",
       "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
       "       'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
       "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
       "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
       "       'AccidentType_at9', 'AccidentSeverityCategory_as2',\n",
       "       'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4',\n",
       "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
       "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
       "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
       "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
       "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
       "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
       "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
       "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
       "       'Hour_22.0', 'Hour_23.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e74dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['air_temperature', 'water_temperature',\n",
    "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
    "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
    "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
    "       'water_level', 'AccidentSeverityCategory_as2',\n",
    "       'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4',\n",
    "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
    "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
    "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
    "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
    "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
    "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
    "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
    "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
    "       'Hour_22.0', 'Hour_23.0']\n",
    "\n",
    "#create data frame for Random Forest prediction\n",
    "df_nn_acc_type = df[df.columns[df.columns.isin(cols)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca9cb056",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_nn_acc_type[df_nn_acc_type.columns[~df_nn_acc_type.columns.isin(['AccidentSeverityCategory_as2', 'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4'])]]\n",
    "y = np.array(df_nn_acc_type[['AccidentSeverityCategory_as2', 'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4']]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93278936",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f3765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78208a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32cb61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.astype(float), X_test.astype(float)\n",
    "y_train, y_test = y_train.astype(float), y_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d416f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.from_numpy(X_test).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45836e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e6a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([64, 3])\n",
      "torch.Size([62, 3])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_loader:\n",
    "    print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aed70408",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(multiClassification, self).__init__()\n",
    "        # Number of input features is 53.\n",
    "        self.layer_1 = nn.Linear(53, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 3) \n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.layer_1(inputs)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.layer_out(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab51287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiClassification(\n",
      "  (layer_1): Linear(in_features=53, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = multiClassification()\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e25f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(y_pred)\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/(y_test.shape[1]*y_test.shape[0])\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ea3ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b25a9287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multiClassification(\n",
       "  (layer_1): Linear(in_features=53, out_features=64, bias=True)\n",
       "  (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (layer_out): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baab1584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.78413 | Acc: 74.384\n",
      "Epoch 002: | Loss: 0.78394 | Acc: 74.382\n",
      "Epoch 003: | Loss: 0.78393 | Acc: 74.384\n",
      "Epoch 004: | Loss: 0.78281 | Acc: 74.830\n",
      "Epoch 005: | Loss: 0.78127 | Acc: 76.775\n",
      "Epoch 006: | Loss: 0.78117 | Acc: 77.132\n",
      "Epoch 007: | Loss: 0.78113 | Acc: 77.137\n",
      "Epoch 008: | Loss: 0.78108 | Acc: 77.286\n",
      "Epoch 009: | Loss: 0.78105 | Acc: 77.263\n",
      "Epoch 010: | Loss: 0.78103 | Acc: 77.310\n",
      "Epoch 011: | Loss: 0.78101 | Acc: 77.372\n",
      "Epoch 012: | Loss: 0.78097 | Acc: 77.404\n",
      "Epoch 013: | Loss: 0.78095 | Acc: 77.398\n",
      "Epoch 014: | Loss: 0.78093 | Acc: 77.381\n",
      "Epoch 015: | Loss: 0.78091 | Acc: 77.410\n",
      "Epoch 016: | Loss: 0.78089 | Acc: 77.434\n",
      "Epoch 017: | Loss: 0.78087 | Acc: 77.459\n",
      "Epoch 018: | Loss: 0.78085 | Acc: 77.476\n",
      "Epoch 019: | Loss: 0.78083 | Acc: 77.530\n",
      "Epoch 020: | Loss: 0.78080 | Acc: 77.500\n",
      "Epoch 021: | Loss: 0.78080 | Acc: 77.526\n",
      "Epoch 022: | Loss: 0.78078 | Acc: 77.553\n",
      "Epoch 023: | Loss: 0.78076 | Acc: 77.539\n",
      "Epoch 024: | Loss: 0.78074 | Acc: 77.621\n",
      "Epoch 025: | Loss: 0.78070 | Acc: 77.533\n",
      "Epoch 026: | Loss: 0.78066 | Acc: 77.652\n",
      "Epoch 027: | Loss: 0.78066 | Acc: 77.657\n",
      "Epoch 028: | Loss: 0.78062 | Acc: 77.655\n",
      "Epoch 029: | Loss: 0.78059 | Acc: 77.611\n",
      "Epoch 030: | Loss: 0.78055 | Acc: 77.690\n",
      "Epoch 031: | Loss: 0.78054 | Acc: 77.678\n",
      "Epoch 032: | Loss: 0.78049 | Acc: 77.623\n",
      "Epoch 033: | Loss: 0.78045 | Acc: 77.707\n",
      "Epoch 034: | Loss: 0.78043 | Acc: 77.741\n",
      "Epoch 035: | Loss: 0.78036 | Acc: 77.799\n",
      "Epoch 036: | Loss: 0.78036 | Acc: 77.816\n",
      "Epoch 037: | Loss: 0.78030 | Acc: 77.866\n",
      "Epoch 038: | Loss: 0.78028 | Acc: 77.750\n",
      "Epoch 039: | Loss: 0.78025 | Acc: 77.897\n",
      "Epoch 040: | Loss: 0.78020 | Acc: 77.878\n",
      "Epoch 041: | Loss: 0.78017 | Acc: 77.929\n",
      "Epoch 042: | Loss: 0.78012 | Acc: 77.952\n",
      "Epoch 043: | Loss: 0.78007 | Acc: 77.907\n",
      "Epoch 044: | Loss: 0.78004 | Acc: 78.030\n",
      "Epoch 045: | Loss: 0.78003 | Acc: 77.955\n",
      "Epoch 046: | Loss: 0.77999 | Acc: 78.008\n",
      "Epoch 047: | Loss: 0.77991 | Acc: 78.064\n",
      "Epoch 048: | Loss: 0.77990 | Acc: 78.071\n",
      "Epoch 049: | Loss: 0.77985 | Acc: 78.077\n",
      "Epoch 050: | Loss: 0.77980 | Acc: 78.068\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        acc = multi_acc(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16684183",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6416abd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_acc(torch.Tensor(np.array(y_pred_list)), torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2f19c9",
   "metadata": {},
   "source": [
    "### ii) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns that are not necessary for prediction\n",
    "cols = ['Unnamed: 0', 'date', 'AccidentInvolvingPedestrian',\n",
    "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
    "        'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
    "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
    "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
    "       'AccidentType_at9']\n",
    "\n",
    "\n",
    "#create data frame for Random Forest prediction\n",
    "df_rf_acc_type = df[df.columns[~df.columns.isin(cols)]]\n",
    "df_rf_acc_type.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5f1dc",
   "metadata": {},
   "source": [
    "**Define targets and labels and run the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6df258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#output label\n",
    "output_class = df_rf_acc_type[[col for col in df_rf_acc_type.columns if col.startswith('Accident')]]\n",
    "target = np.array(output_class)\n",
    "\n",
    "#input features\n",
    "features = df_rf_acc_type[df_rf_acc_type.columns[~df_rf_acc_type.columns.isin(output_class)]]\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "#split dataset into training and testing\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "target, test_size = 0.33, random_state = 32)\n",
    "\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "clf = RandomForestClassifier(n_estimators= 250)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train_features, train_target)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_target, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e30e51",
   "metadata": {},
   "source": [
    "### - Accident Type prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a52a84",
   "metadata": {},
   "source": [
    "### i) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d749cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae3d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Unnamed: 0', 'date', 'AccidentInvolvingPedestrian',\n",
    "       'AccidentInvolvingBicycle', 'AccidentInvolvingMotorcycle', 'Accident',\n",
    "        'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
    "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
    "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
    "       'AccidentType_at9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a401d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame for Random Forest prediction\n",
    "df_nn_acc_type = df[df.columns[~df.columns.isin(cols)]]\n",
    "\n",
    "X = df_nn_acc_type[df_nn_acc_type.columns[~df_nn_acc_type.columns.isin(cols)]]\n",
    "y = df_nn_acc_type[['AccidentSeverityCategory_as2', 'AccidentSeverityCategory_as3', 'AccidentSeverityCategory_as4']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=69)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db990c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = trainData(torch.FloatTensor(X_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "\n",
    "test_data = testData(torch.FloatTensor(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f994572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 53.\n",
    "        self.layer_1 = nn.Linear(53, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f0f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = binaryClassification()\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "print(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddecd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "\n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e512312",
   "metadata": {},
   "source": [
    "### ii) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of columns that are necessary for prediction\n",
    "cols = ['air_temperature', 'water_temperature',\n",
    "       'wind_gust_max_10min', 'wind_speed_avg_10min', 'wind_force_avg_10min',\n",
    "       'wind_direction', 'windchill', 'barometric_pressure_qfe',\n",
    "       'precipitation', 'dew_point', 'global_radiation', 'humidity',\n",
    "       'water_level', 'AccidentType_at00', 'AccidentType_at1', 'AccidentType_at2',\n",
    "       'AccidentType_at3', 'AccidentType_at4', 'AccidentType_at5',\n",
    "       'AccidentType_at6', 'AccidentType_at7', 'AccidentType_at8',\n",
    "       'AccidentType_at9',\n",
    "       'WeekDay_Monday', 'WeekDay_Saturday', 'WeekDay_Sunday',\n",
    "       'WeekDay_Thursday', 'WeekDay_Tuesday', 'WeekDay_Wednesday', 'Month_2.0',\n",
    "       'Month_3.0', 'Month_4.0', 'Month_5.0', 'Month_6.0', 'Month_7.0',\n",
    "       'Month_8.0', 'Month_9.0', 'Month_10.0', 'Month_11.0', 'Month_12.0',\n",
    "       'Hour_1.0', 'Hour_2.0', 'Hour_3.0', 'Hour_4.0', 'Hour_5.0', 'Hour_6.0',\n",
    "       'Hour_7.0', 'Hour_8.0', 'Hour_9.0', 'Hour_10.0', 'Hour_11.0',\n",
    "       'Hour_12.0', 'Hour_13.0', 'Hour_14.0', 'Hour_15.0', 'Hour_16.0',\n",
    "       'Hour_17.0', 'Hour_18.0', 'Hour_19.0', 'Hour_20.0', 'Hour_21.0',\n",
    "       'Hour_22.0', 'Hour_23.0']\n",
    "\n",
    "#Create data frame for Random Forest prediction\n",
    "df_rf_acc_sev = df[df.columns[df.columns.isin(cols)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c4351",
   "metadata": {},
   "source": [
    "**Define targets and labels and run the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173daa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output label\n",
    "output_class = df_rf_acc_sev[[col for col in df_rf_acc_sev.columns if col.startswith('Accident')]]\n",
    "target = np.array(output_class)\n",
    "\n",
    "#input features\n",
    "features = df_rf_acc_sev[df_rf_acc_sev.columns[~df_rf_acc_sev.columns.isin(output_class)]]\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "#split dataset into training and testing\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, \n",
    "target, test_size = 0.25, random_state = 11)\n",
    "\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "clf = RandomForestClassifier(n_estimators= 130)\n",
    "\n",
    "# Train the model on training data\n",
    "clf.fit(train_features, train_target)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test_target, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
